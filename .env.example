# Lab-Verse Agent - Hugging Face Self-Hosted Configuration
# Copy this to .env.production and fill in your actual values

# ===== BITBUCKET CONFIGURATION =====
PIPELINE_PLATFORM=bitbucket
BITBUCKET_WORKSPACE=lab-verse-monitaring
BITBUCKET_USERNAME=your-email@atlassian.com
BITBUCKET_APP_PASSWORD=your-64-character-app-password

# ===== HUGGING FACE CONFIGURATION =====
# Get your HF token from: https://huggingface.co/settings/tokens
# Already in GitHub/Colab? Paste it here:
HF_TOKEN=hf_your-token-here

# Device: cuda (GPU), cpu (CPU only), or auto-detect
HF_DEVICE=cuda

# Quantization (reduce VRAM usage)
HF_LOAD_IN_8BIT=true    # Saves 75% VRAM (recommended)
HF_LOAD_IN_4BIT=false   # Saves 87.5% VRAM (slower)

# Model cache directory
HF_CACHE_DIR=./models

# Model IDs (change if using different models)
HF_MODEL_DIAGNOSTIC=mistralai/Mistral-7B-Instruct-v0.3
HF_MODEL_PLANNER=microsoft/phi-2
HF_MODEL_EXECUTOR=TinyLlama/TinyLlama-1.1B-Chat-v1.0
HF_MODEL_VALIDATOR=mistralai/Mistral-7B-Instruct-v0.3

# ===== AGENT CONFIGURATION =====
ENVIRONMENT=production
LOG_LEVEL=INFO
MAX_RETRIES=3
APPROVAL_TIMEOUT_SECONDS=3600
PIPELINE_WAIT_TIMEOUT_SECONDS=1800

# ===== SECURITY =====
ENABLE_HUMAN_APPROVAL=true
ENABLE_AUDIT_LOGGING=true
ENABLE_RATE_LIMITING=true

# ===== INFRASTRUCTURE =====
KUBERNETES_NAMESPACE=lab-verse-monitoring
ENABLE_METRICS=true
METRICS_PORT=8001
