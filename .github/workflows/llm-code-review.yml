name: LLM-Powered Code Review

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  issues: write

jobs:
  # ========================================================================
  # STEP 1: Collect Findings
  # ========================================================================
  collect-findings:
    name: Collect Code Review Findings
    runs-on: ubuntu-latest
    outputs:
      findings_file: ${{ steps.collect.outputs.findings_file }}

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: 'recursive'
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install bandit ruff mypy safety

      - name: Run static analysis
        id: collect
        continue-on-error: true
        run: |
          mkdir -p artifacts
          # Run static analysis tools
          bandit -r src/ -f json -o artifacts/bandit.json || echo "bandit failed"
          ruff check src/ --output-format=json > artifacts/ruff.json || echo "ruff failed"
          # mypy src/ --json-report artifacts/ || echo "mypy failed"
          # safety check --json > artifacts/safety.json || echo "safety failed"

          # Ensure findings.json exists even if tools fail
          echo '{"findings": []}' > artifacts/findings.json
          echo "findings_file=artifacts/findings.json" >> $GITHUB_OUTPUT

      - name: Upload findings
        uses: actions/upload-artifact@v4
        with:
          name: findings
          path: artifacts/
          retention-days: 7

  # ========================================================================
  # STEP 2: Reasoning + Coding + Testing (Combined for optimization)
  # ========================================================================
  process-and-test:
    name: Process Findings and Test
    runs-on: ubuntu-latest
    needs: [collect-findings]
    outputs:
      tests_passed: ${{ steps.test.outputs.tests_passed }}
      test_exit_code: ${{ steps.test.outputs.test_exit_code }}

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: 'recursive'
          fetch-depth: 0

      - name: Free Disk Space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf "/usr/local/share/boost"
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /usr/share/swift
          sudo rm -rf /usr/local/share/powershell
          sudo rm -rf /etc/mysql
          sudo rm -rf /usr/local/lib/node_modules
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          docker image prune -af

      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          sleep 10
          ollama pull deepseek-r1:1.5b
          ollama pull qwen2.5-coder:1.5b

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install package
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Download findings
        uses: actions/download-artifact@v4
        with:
          name: findings
          path: artifacts/

      - name: Run orchestrator (reasoning + coding)
        run: |
          pr-fix-agent --mode reasoning \
            --findings artifacts/findings.json \
            --output artifacts/proposals.json

          pr-fix-agent --mode coding \
            --proposals artifacts/proposals.json \
            --output artifacts/fixes \
            --apply

      - name: Run tests
        id: test
        run: |
          set +e
          pytest tests/ -v \
            --json-report \
            --json-report-file=artifacts/test-results.json \
            --tb=short
          TEST_EXIT_CODE=$?
          set -e

          echo "test_exit_code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT
          if [ $TEST_EXIT_CODE -eq 0 ] && [ -f artifacts/test-results.json ]; then
            echo "tests_passed=true" >> $GITHUB_OUTPUT
          else
            echo "tests_passed=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: process-results
          path: |
            artifacts/proposals.json
            artifacts/test-results.json
            artifacts/fixes/

  # ========================================================================
  # STEP 3: Create PR
  # ========================================================================
  create-pr:
    name: Create Pull Request
    runs-on: ubuntu-latest
    needs: [process-and-test]
    if: always()

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: 'recursive'
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install package
        run: |
          python -m pip install --upgrade pip
          pip install -e .

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: process-results
          path: artifacts/

      - name: Generate PR body
        run: |
          pr-fix-agent --mode generate-pr \
            --proposals artifacts/proposals.json \
            --test-results artifacts/test-results.json \
            --output pr-body.md

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v7
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "ðŸ¤– Auto-fix: Code review findings"
          title: "ðŸ¤– Auto-fix: Code review findings ${{ needs.process-and-test.outputs.tests_passed == 'true' && 'âœ…' || 'âŒ' }}"
          body-path: pr-body.md
          branch: auto-fix/code-review-${{ github.run_number }}
          labels: |
            automated-fix
            code-review
            ${{ needs.process-and-test.outputs.tests_passed == 'true' && 'tests-passed' || 'tests-failed' }}
          draft: ${{ needs.process-and-test.outputs.tests_passed == 'false' }}
          delete-branch: true

  report-summary:
    name: Report Summary
    runs-on: ubuntu-latest
    needs: [process-and-test, create-pr]
    if: always()

    steps:
      - name: Generate summary
        run: |
          echo "## ðŸ¤– LLM Code Review Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests**: ${{ needs.process-and-test.outputs.tests_passed == 'true' && 'âœ… PASSED' || 'âŒ FAILED' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **PR Created**: ${{ create-pr.result == 'success' && 'âœ…' || 'âŒ' }}" >> $GITHUB_STEP_SUMMARY
