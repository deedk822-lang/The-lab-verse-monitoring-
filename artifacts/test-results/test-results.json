{"created": 1769899096.5755217, "duration": 0.905548095703125, "exitcode": 1, "root": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-", "environment": {}, "summary": {"passed": 43, "failed": 6, "error": 3, "total": 52, "collected": 52}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests", "type": "Dir"}]}, {"nodeid": "tests/test_analyzer.py::TestPRErrorAnalyzerReal", "outcome": "passed", "result": [{"nodeid": "tests/test_analyzer.py::TestPRErrorAnalyzerReal::test_analyze_error_basic", "type": "Function", "lineno": 31}, {"nodeid": "tests/test_analyzer.py::TestPRErrorAnalyzerReal::test_extract_root_cause", "type": "Function", "lineno": 41}]}, {"nodeid": "tests/test_analyzer.py", "outcome": "passed", "result": [{"nodeid": "tests/test_analyzer.py::TestPRErrorAnalyzerReal", "type": "Class"}]}, {"nodeid": "tests/test_fixer.py::TestPRErrorFixerReal", "outcome": "passed", "result": [{"nodeid": "tests/test_fixer.py::TestPRErrorFixerReal::test_fix_missing_file_creates_file", "type": "Function", "lineno": 40}, {"nodeid": "tests/test_fixer.py::TestPRErrorFixerReal::test_fix_blocks_path_traversal", "type": "Function", "lineno": 50}, {"nodeid": "tests/test_fixer.py::TestPRErrorFixerReal::test_fix_missing_dependency_adds_to_requirements", "type": "Function", "lineno": 58}]}, {"nodeid": "tests/test_fixer.py", "outcome": "passed", "result": [{"nodeid": "tests/test_fixer.py::TestPRErrorFixerReal", "type": "Class"}]}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage", "outcome": "passed", "result": [{"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_provider_uses_token_from_config", "type": "Function", "lineno": 53}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_provider_warns_without_token", "type": "Function", "lineno": 74}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_initialize_from_env_uses_hf_token", "type": "Function", "lineno": 92}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_initialize_from_env_warns_without_token", "type": "Function", "lineno": 107}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_model_loading_passes_token_to_transformers", "type": "Function", "lineno": 120}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_authentication_error_gives_helpful_message", "type": "Function", "lineno": 156}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_rate_limit_error_suggests_using_token", "type": "Function", "lineno": 187}]}, {"nodeid": "tests/test_integration.py::TestProviderInitialization", "outcome": "passed", "result": [{"nodeid": "tests/test_integration.py::TestProviderInitialization::test_factory_creates_openai_provider", "type": "Function", "lineno": 218}, {"nodeid": "tests/test_integration.py::TestProviderInitialization::test_factory_creates_huggingface_provider_with_token", "type": "Function", "lineno": 234}, {"nodeid": "tests/test_integration.py::TestProviderInitialization::test_initialize_from_env_openai", "type": "Function", "lineno": 251}]}, {"nodeid": "tests/test_integration.py::TestRedisSharedState", "outcome": "passed", "result": [{"nodeid": "tests/test_integration.py::TestRedisSharedState::test_rate_limiter_allows_under_limit", "type": "Coroutine", "lineno": 271}, {"nodeid": "tests/test_integration.py::TestRedisSharedState::test_rate_limiter_blocks_over_limit", "type": "Coroutine", "lineno": 282}, {"nodeid": "tests/test_integration.py::TestRedisSharedState::test_dedupe_cache_detects_duplicate", "type": "Coroutine", "lineno": 296}]}, {"nodeid": "tests/test_integration.py::TestSecurityIntegration", "outcome": "passed", "result": [{"nodeid": "tests/test_integration.py::TestSecurityIntegration::test_sanitized_prompt_prevents_injection", "type": "Coroutine", "lineno": 324}, {"nodeid": "tests/test_integration.py::TestSecurityIntegration::test_ssrf_blocker_prevents_private_ip_access", "type": "Coroutine", "lineno": 339}]}, {"nodeid": "tests/test_integration.py", "outcome": "passed", "result": [{"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage", "type": "Class"}, {"nodeid": "tests/test_integration.py::TestProviderInitialization", "type": "Class"}, {"nodeid": "tests/test_integration.py::TestRedisSharedState", "type": "Class"}, {"nodeid": "tests/test_integration.py::TestSecurityIntegration", "type": "Class"}]}, {"nodeid": "tests/test_main.py::TestClient", "outcome": "passed", "result": []}, {"nodeid": "tests/test_main.py", "outcome": "passed", "result": [{"nodeid": "tests/test_main.py::TestClient", "type": "Class"}, {"nodeid": "tests/test_main.py::test_health_endpoint", "type": "Function", "lineno": 13}, {"nodeid": "tests/test_main.py::test_bitbucket_status_endpoint", "type": "Function", "lineno": 22}, {"nodeid": "tests/test_main.py::test_jira_status_endpoint", "type": "Function", "lineno": 30}, {"nodeid": "tests/test_main.py::test_bitbucket_webhook_success", "type": "Function", "lineno": 38}, {"nodeid": "tests/test_main.py::test_async_functionality", "type": "Coroutine", "lineno": 48}]}, {"nodeid": "tests/test_security.py::TestClient", "outcome": "passed", "result": []}, {"nodeid": "tests/test_security.py::TestPromptSanitization", "outcome": "passed", "result": [{"nodeid": "tests/test_security.py::TestPromptSanitization::test_clean_prompt_passes", "type": "Function", "lineno": 34}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_injection_pattern_detected", "type": "Function", "lineno": 40}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_strict_mode_raises_exception", "type": "Function", "lineno": 55}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_soft_mode_filters_patterns", "type": "Function", "lineno": 62}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_unicode_normalization", "type": "Function", "lineno": 70}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_length_truncation", "type": "Function", "lineno": 79}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_system_message_removal", "type": "Function", "lineno": 86}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_context_sanitization", "type": "Function", "lineno": 94}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_webhook_payload_sanitization", "type": "Function", "lineno": 110}]}, {"nodeid": "tests/test_security.py::TestSSRFProtection", "outcome": "passed", "result": [{"nodeid": "tests/test_security.py::TestSSRFProtection::test_private_ip_detection", "type": "Function", "lineno": 129}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_public_ip_allowed", "type": "Function", "lineno": 145}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_metadata_endpoint_blocked", "type": "Function", "lineno": 158}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_invalid_scheme_rejected", "type": "Function", "lineno": 165}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_domain_allowlist", "type": "Function", "lineno": 180}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_domain_blocklist", "type": "Function", "lineno": 193}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_dns_rebinding_protection", "type": "Function", "lineno": 201}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_safe_session_creation", "type": "Function", "lineno": 215}]}, {"nodeid": "tests/test_security.py::TestWebhookSecurity", "outcome": "passed", "result": [{"nodeid": "tests/test_security.py::TestWebhookSecurity::test_webhook_valid_signature", "type": "Function", "lineno": 231}, {"nodeid": "tests/test_security.py::TestWebhookSecurity::test_webhook_invalid_signature", "type": "Function", "lineno": 251}, {"nodeid": "tests/test_security.py::TestWebhookSecurity::test_webhook_missing_signature", "type": "Function", "lineno": 270}]}, {"nodeid": "tests/test_security.py::TestRateLimiting", "outcome": "passed", "result": [{"nodeid": "tests/test_security.py::TestRateLimiting::test_rate_limit_allows_under_threshold", "type": "Coroutine", "lineno": 288}, {"nodeid": "tests/test_security.py::TestRateLimiting::test_rate_limit_blocks_over_threshold", "type": "Coroutine", "lineno": 299}]}, {"nodeid": "tests/test_security.py::TestWebhookDeduplication", "outcome": "passed", "result": [{"nodeid": "tests/test_security.py::TestWebhookDeduplication::test_dedupe_detects_duplicate", "type": "Coroutine", "lineno": 317}]}, {"nodeid": "tests/test_security.py::TestAuthenticationSecurity", "outcome": "passed", "result": [{"nodeid": "tests/test_security.py::TestAuthenticationSecurity::test_missing_auth_key_rejected", "type": "Coroutine", "lineno": 342}, {"nodeid": "tests/test_security.py::TestAuthenticationSecurity::test_invalid_auth_key_rejected", "type": "Coroutine", "lineno": 355}, {"nodeid": "tests/test_security.py::TestAuthenticationSecurity::test_valid_auth_key_accepted", "type": "Coroutine", "lineno": 368}]}, {"nodeid": "tests/test_security.py::TestSecurityIntegration", "outcome": "passed", "result": [{"nodeid": "tests/test_security.py::TestSecurityIntegration::test_end_to_end_webhook_security", "type": "Coroutine", "lineno": 381}]}, {"nodeid": "tests/test_security.py", "outcome": "passed", "result": [{"nodeid": "tests/test_security.py::TestClient", "type": "Class"}, {"nodeid": "tests/test_security.py::TestPromptSanitization", "type": "Class"}, {"nodeid": "tests/test_security.py::TestSSRFProtection", "type": "Class"}, {"nodeid": "tests/test_security.py::TestWebhookSecurity", "type": "Class"}, {"nodeid": "tests/test_security.py::TestRateLimiting", "type": "Class"}, {"nodeid": "tests/test_security.py::TestWebhookDeduplication", "type": "Class"}, {"nodeid": "tests/test_security.py::TestAuthenticationSecurity", "type": "Class"}, {"nodeid": "tests/test_security.py::TestSecurityIntegration", "type": "Class"}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/test_analyzer.py", "type": "Module"}, {"nodeid": "tests/test_fixer.py", "type": "Module"}, {"nodeid": "tests/test_integration.py", "type": "Module"}, {"nodeid": "tests/test_main.py", "type": "Module"}, {"nodeid": "tests/test_security.py", "type": "Module"}]}], "tests": [{"nodeid": "tests/test_analyzer.py::TestPRErrorAnalyzerReal::test_analyze_error_basic", "lineno": 31, "outcome": "passed", "keywords": ["test_analyze_error_basic", "TestPRErrorAnalyzerReal", "test_analyzer.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.000647495999999137, "outcome": "passed"}, "call": {"duration": 0.0001990810000052079, "outcome": "passed"}, "teardown": {"duration": 0.00015337499996803672, "outcome": "passed"}}, {"nodeid": "tests/test_analyzer.py::TestPRErrorAnalyzerReal::test_extract_root_cause", "lineno": 41, "outcome": "passed", "keywords": ["test_extract_root_cause", "TestPRErrorAnalyzerReal", "test_analyzer.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0004454299999565592, "outcome": "passed"}, "call": {"duration": 0.00013271699998540498, "outcome": "passed"}, "teardown": {"duration": 0.00013684499998589672, "outcome": "passed"}}, {"nodeid": "tests/test_fixer.py::TestPRErrorFixerReal::test_fix_missing_file_creates_file", "lineno": 40, "outcome": "failed", "keywords": ["test_fix_missing_file_creates_file", "TestPRErrorFixerReal", "test_fixer.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0025473950000218792, "outcome": "passed"}, "call": {"duration": 0.0006077820000314205, "outcome": "failed", "crash": {"path": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/src/pr_fix_agent/analyzer.py", "lineno": 226, "message": "TypeError: SecurityValidator.validate_path() missing 1 required positional argument: 'base_dir'"}, "traceback": [{"path": "tests/test_fixer.py", "lineno": 45, "message": "in test_fix_missing_file_creates_file"}, {"path": "src/pr_fix_agent/analyzer.py", "lineno": 226, "message": "in fix_missing_file_error"}], "longrepr": "tests/test_fixer.py:45: in test_fix_missing_file_creates_file\n    result = fixer.fix_missing_file_error(error)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsrc/pr_fix_agent/analyzer.py:226: in fix_missing_file_error\n    file_path = self.validator.validate_path(filename)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: SecurityValidator.validate_path() missing 1 required positional argument: 'base_dir'"}, "teardown": {"duration": 0.00016846399995529282, "outcome": "passed"}}, {"nodeid": "tests/test_fixer.py::TestPRErrorFixerReal::test_fix_blocks_path_traversal", "lineno": 50, "outcome": "failed", "keywords": ["test_fix_blocks_path_traversal", "TestPRErrorFixerReal", "test_fixer.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0006543889999761632, "outcome": "passed"}, "call": {"duration": 0.0003345129999843266, "outcome": "failed", "crash": {"path": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/src/pr_fix_agent/analyzer.py", "lineno": 226, "message": "TypeError: SecurityValidator.validate_path() missing 1 required positional argument: 'base_dir'"}, "traceback": [{"path": "tests/test_fixer.py", "lineno": 55, "message": "in test_fix_blocks_path_traversal"}, {"path": "src/pr_fix_agent/analyzer.py", "lineno": 226, "message": "in fix_missing_file_error"}], "longrepr": "tests/test_fixer.py:55: in test_fix_blocks_path_traversal\n    result = fixer.fix_missing_file_error(error)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsrc/pr_fix_agent/analyzer.py:226: in fix_missing_file_error\n    file_path = self.validator.validate_path(filename)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: SecurityValidator.validate_path() missing 1 required positional argument: 'base_dir'"}, "teardown": {"duration": 0.00015926699995816307, "outcome": "passed"}}, {"nodeid": "tests/test_fixer.py::TestPRErrorFixerReal::test_fix_missing_dependency_adds_to_requirements", "lineno": 58, "outcome": "failed", "keywords": ["test_fix_missing_dependency_adds_to_requirements", "TestPRErrorFixerReal", "test_fixer.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0006410740000433179, "outcome": "passed"}, "call": {"duration": 0.0004593659999727606, "outcome": "failed", "crash": {"path": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/src/pr_fix_agent/analyzer.py", "lineno": 286, "message": "AttributeError: 'SecurityValidator' object has no attribute 'validate_module_name'"}, "traceback": [{"path": "tests/test_fixer.py", "lineno": 66, "message": "in test_fix_missing_dependency_adds_to_requirements"}, {"path": "src/pr_fix_agent/analyzer.py", "lineno": 286, "message": "in fix_missing_dependency"}], "longrepr": "tests/test_fixer.py:66: in test_fix_missing_dependency_adds_to_requirements\n    result = fixer.fix_missing_dependency(error)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsrc/pr_fix_agent/analyzer.py:286: in fix_missing_dependency\n    validated_module = self.validator.validate_module_name(module_name)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'SecurityValidator' object has no attribute 'validate_module_name'"}, "teardown": {"duration": 0.00015834500004530128, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_provider_uses_token_from_config", "lineno": 53, "outcome": "passed", "keywords": ["test_provider_uses_token_from_config", "TestHuggingFaceTokenUsage", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0003294539999956214, "outcome": "passed"}, "call": {"duration": 0.00016456700001299396, "outcome": "passed"}, "teardown": {"duration": 0.00012764699999934237, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_provider_warns_without_token", "lineno": 74, "outcome": "passed", "keywords": ["test_provider_warns_without_token", "TestHuggingFaceTokenUsage", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0003711609999754728, "outcome": "passed"}, "call": {"duration": 0.0002657549999867115, "outcome": "passed", "log": [{"name": "agent.tools.llm_provider", "msg": "HuggingFace token (HF_TOKEN) not provided. This may cause issues with:\n  - Downloading models\n  - Accessing gated models\n  - Rate limits\nSet HF_TOKEN environment variable or pass api_key in config.", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../agent/tools/llm_provider.py", "filename": "llm_provider.py", "module": "llm_provider", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 130, "funcName": "__init__", "created": 1769899096.2560997, "msecs": 256.0, "relativeCreated": 1016.0975456237793, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 0.00013556300001482668, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_initialize_from_env_uses_hf_token", "lineno": 92, "outcome": "passed", "keywords": ["test_initialize_from_env_uses_hf_token", "TestHuggingFaceTokenUsage", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0002623080000034861, "outcome": "passed"}, "call": {"duration": 0.00017642899996417327, "outcome": "passed"}, "teardown": {"duration": 0.00013417999997500374, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_initialize_from_env_warns_without_token", "lineno": 107, "outcome": "passed", "keywords": ["test_initialize_from_env_warns_without_token", "TestHuggingFaceTokenUsage", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00034595500000023094, "outcome": "passed"}, "call": {"duration": 0.00028684499994824364, "outcome": "passed", "log": [{"name": "agent.tools.llm_provider", "msg": "HF_TOKEN not set. HuggingFace provider will work but:\n  - Cannot download models that require authentication\n  - Lower rate limits apply\n  - Gated models will fail\nGet your token from: https://huggingface.co/settings/tokens", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../agent/tools/llm_provider.py", "filename": "llm_provider.py", "module": "llm_provider", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 524, "funcName": "initialize_from_env", "created": 1769899096.2581415, "msecs": 258.0, "relativeCreated": 1018.1393623352051, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}, {"name": "agent.tools.llm_provider", "msg": "HuggingFace token (HF_TOKEN) not provided. This may cause issues with:\n  - Downloading models\n  - Accessing gated models\n  - Rate limits\nSet HF_TOKEN environment variable or pass api_key in config.", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../agent/tools/llm_provider.py", "filename": "llm_provider.py", "module": "llm_provider", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 130, "funcName": "__init__", "created": 1769899096.2582107, "msecs": 258.0, "relativeCreated": 1018.2085037231445, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 0.0001386989999900834, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_model_loading_passes_token_to_transformers", "lineno": 120, "outcome": "failed", "keywords": ["test_model_loading_passes_token_to_transformers", "TestHuggingFaceTokenUsage", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00023942600000737002, "outcome": "passed"}, "call": {"duration": 0.0005129550000333438, "outcome": "failed", "crash": {"path": "<frozen importlib._bootstrap>", "lineno": 1140, "message": "ModuleNotFoundError: No module named 'transformers'"}, "traceback": [{"path": "tests/test_integration.py", "lineno": 134, "message": "in test_model_loading_passes_token_to_transformers"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/unittest/mock.py", "lineno": 1430, "message": "in __enter__"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/pkgutil.py", "lineno": 700, "message": "in resolve_name"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/importlib/__init__.py", "lineno": 126, "message": "in import_module"}, {"path": "<frozen importlib._bootstrap>", "lineno": 1204, "message": "in _gcd_import"}, {"path": "<frozen importlib._bootstrap>", "lineno": 1176, "message": "in _find_and_load"}, {"path": "<frozen importlib._bootstrap>", "lineno": 1140, "message": "in _find_and_load_unlocked"}], "longrepr": "tests/test_integration.py:134: in test_model_loading_passes_token_to_transformers\n    with patch('transformers.AutoTokenizer', create=True) as mock_tokenizer_class:\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/unittest/mock.py:1430: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/pkgutil.py:700: in resolve_name\n    mod = importlib.import_module(modname)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1204: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1176: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1140: in _find_and_load_unlocked\n    ???\nE   ModuleNotFoundError: No module named 'transformers'"}, "teardown": {"duration": 0.00020897999996805083, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_authentication_error_gives_helpful_message", "lineno": 156, "outcome": "failed", "keywords": ["test_authentication_error_gives_helpful_message", "TestHuggingFaceTokenUsage", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00028568199996925614, "outcome": "passed"}, "call": {"duration": 0.0003862390000222149, "outcome": "failed", "crash": {"path": "<frozen importlib._bootstrap>", "lineno": 1140, "message": "ModuleNotFoundError: No module named 'transformers'"}, "traceback": [{"path": "tests/test_integration.py", "lineno": 170, "message": "in test_authentication_error_gives_helpful_message"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/unittest/mock.py", "lineno": 1430, "message": "in __enter__"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/pkgutil.py", "lineno": 700, "message": "in resolve_name"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/importlib/__init__.py", "lineno": 126, "message": "in import_module"}, {"path": "<frozen importlib._bootstrap>", "lineno": 1204, "message": "in _gcd_import"}, {"path": "<frozen importlib._bootstrap>", "lineno": 1176, "message": "in _find_and_load"}, {"path": "<frozen importlib._bootstrap>", "lineno": 1140, "message": "in _find_and_load_unlocked"}], "longrepr": "tests/test_integration.py:170: in test_authentication_error_gives_helpful_message\n    with patch('transformers.AutoTokenizer', create=True) as mock_tokenizer_class:\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/unittest/mock.py:1430: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/pkgutil.py:700: in resolve_name\n    mod = importlib.import_module(modname)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1204: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1176: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1140: in _find_and_load_unlocked\n    ???\nE   ModuleNotFoundError: No module named 'transformers'"}, "teardown": {"duration": 0.00016716200002520054, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestHuggingFaceTokenUsage::test_rate_limit_error_suggests_using_token", "lineno": 187, "outcome": "failed", "keywords": ["test_rate_limit_error_suggests_using_token", "TestHuggingFaceTokenUsage", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00025847199998452197, "outcome": "passed"}, "call": {"duration": 0.0004203130000064448, "outcome": "failed", "crash": {"path": "<frozen importlib._bootstrap>", "lineno": 1140, "message": "ModuleNotFoundError: No module named 'transformers'"}, "traceback": [{"path": "tests/test_integration.py", "lineno": 201, "message": "in test_rate_limit_error_suggests_using_token"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/unittest/mock.py", "lineno": 1430, "message": "in __enter__"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/pkgutil.py", "lineno": 700, "message": "in resolve_name"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/importlib/__init__.py", "lineno": 126, "message": "in import_module"}, {"path": "<frozen importlib._bootstrap>", "lineno": 1204, "message": "in _gcd_import"}, {"path": "<frozen importlib._bootstrap>", "lineno": 1176, "message": "in _find_and_load"}, {"path": "<frozen importlib._bootstrap>", "lineno": 1140, "message": "in _find_and_load_unlocked"}], "log": [{"name": "agent.tools.llm_provider", "msg": "HuggingFace token (HF_TOKEN) not provided. This may cause issues with:\n  - Downloading models\n  - Accessing gated models\n  - Rate limits\nSet HF_TOKEN environment variable or pass api_key in config.", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../agent/tools/llm_provider.py", "filename": "llm_provider.py", "module": "llm_provider", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 130, "funcName": "__init__", "created": 1769899096.3797867, "msecs": 379.0, "relativeCreated": 1139.784574508667, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}], "longrepr": "tests/test_integration.py:201: in test_rate_limit_error_suggests_using_token\n    with patch('transformers.AutoTokenizer', create=True) as mock_tokenizer_class:\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/unittest/mock.py:1430: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/pkgutil.py:700: in resolve_name\n    mod = importlib.import_module(modname)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1204: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1176: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1140: in _find_and_load_unlocked\n    ???\nE   ModuleNotFoundError: No module named 'transformers'"}, "teardown": {"duration": 0.00019896100002370076, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestProviderInitialization::test_factory_creates_openai_provider", "lineno": 218, "outcome": "passed", "keywords": ["test_factory_creates_openai_provider", "TestProviderInitialization", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00028533099998639955, "outcome": "passed"}, "call": {"duration": 0.00015321500001164168, "outcome": "passed"}, "teardown": {"duration": 0.0001294909999955962, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestProviderInitialization::test_factory_creates_huggingface_provider_with_token", "lineno": 234, "outcome": "passed", "keywords": ["test_factory_creates_huggingface_provider_with_token", "TestProviderInitialization", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0002563970000437621, "outcome": "passed"}, "call": {"duration": 0.0001458419999949001, "outcome": "passed"}, "teardown": {"duration": 0.00012978199998769924, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestProviderInitialization::test_initialize_from_env_openai", "lineno": 251, "outcome": "passed", "keywords": ["test_initialize_from_env_openai", "TestProviderInitialization", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0002700130000334866, "outcome": "passed"}, "call": {"duration": 0.00015705299995261157, "outcome": "passed"}, "teardown": {"duration": 0.00012697699997943346, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestRedisSharedState::test_rate_limiter_allows_under_limit", "lineno": 271, "outcome": "error", "keywords": ["test_rate_limiter_allows_under_limit", "asyncio", "pytestmark", "TestRedisSharedState", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0002645530000222607, "outcome": "failed", "crash": {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/_pytest/fixtures.py", "lineno": 1188, "message": "pytest.PytestRemovedIn9Warning: 'test_rate_limiter_allows_under_limit' requested an async fixture 'redis_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\nSee: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture"}, "traceback": [{"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py", "lineno": 458, "message": "in setup"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py", "lineno": 728, "message": "in pytest_fixture_setup"}], "longrepr": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py:458: in setup\n    return super().setup()\n           ^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py:728: in pytest_fixture_setup\n    return (yield)\n            ^^^^^\nE   pytest.PytestRemovedIn9Warning: 'test_rate_limiter_allows_under_limit' requested an async fixture 'redis_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\nE   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture"}, "teardown": {"duration": 0.00012863000000606917, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestRedisSharedState::test_rate_limiter_blocks_over_limit", "lineno": 282, "outcome": "error", "keywords": ["test_rate_limiter_blocks_over_limit", "asyncio", "pytestmark", "TestRedisSharedState", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00024917399997548273, "outcome": "failed", "crash": {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/_pytest/fixtures.py", "lineno": 1188, "message": "pytest.PytestRemovedIn9Warning: 'test_rate_limiter_blocks_over_limit' requested an async fixture 'redis_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\nSee: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture"}, "traceback": [{"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py", "lineno": 458, "message": "in setup"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py", "lineno": 728, "message": "in pytest_fixture_setup"}], "longrepr": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py:458: in setup\n    return super().setup()\n           ^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py:728: in pytest_fixture_setup\n    return (yield)\n            ^^^^^\nE   pytest.PytestRemovedIn9Warning: 'test_rate_limiter_blocks_over_limit' requested an async fixture 'redis_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\nE   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture"}, "teardown": {"duration": 0.0001274879999755285, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestRedisSharedState::test_dedupe_cache_detects_duplicate", "lineno": 296, "outcome": "error", "keywords": ["test_dedupe_cache_detects_duplicate", "asyncio", "pytestmark", "TestRedisSharedState", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00022791499998220388, "outcome": "failed", "crash": {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/_pytest/fixtures.py", "lineno": 1188, "message": "pytest.PytestRemovedIn9Warning: 'test_dedupe_cache_detects_duplicate' requested an async fixture 'redis_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\nSee: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture"}, "traceback": [{"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py", "lineno": 458, "message": "in setup"}, {"path": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py", "lineno": 728, "message": "in pytest_fixture_setup"}], "longrepr": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py:458: in setup\n    return super().setup()\n           ^^^^^^^^^^^^^^^\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pytest_asyncio/plugin.py:728: in pytest_fixture_setup\n    return (yield)\n            ^^^^^\nE   pytest.PytestRemovedIn9Warning: 'test_dedupe_cache_detects_duplicate' requested an async fixture 'redis_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\nE   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture"}, "teardown": {"duration": 0.00015271500001290406, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestSecurityIntegration::test_sanitized_prompt_prevents_injection", "lineno": 324, "outcome": "passed", "keywords": ["test_sanitized_prompt_prevents_injection", "asyncio", "pytestmark", "TestSecurityIntegration", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0005139369999938026, "outcome": "passed"}, "call": {"duration": 0.001007796999999755, "outcome": "passed", "log": [{"name": "vaal_ai_empire.api.sanitizers", "msg": "Dangerous patterns detected: ['(?i)(ignore|forget|disregard)\\\\s+(previous|above|all|everything|instructions|prompts|rules)\\\\b']", "args": null, "levelname": "ERROR", "levelno": 40, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../vaal_ai_empire/api/sanitizers.py", "filename": "sanitizers.py", "module": "sanitizers", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 73, "funcName": "sanitize_prompt", "created": 1769899096.485229, "msecs": 485.0, "relativeCreated": 1245.2268600463867, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 0.00037775399999873116, "outcome": "passed"}}, {"nodeid": "tests/test_integration.py::TestSecurityIntegration::test_ssrf_blocker_prevents_private_ip_access", "lineno": 339, "outcome": "passed", "keywords": ["test_ssrf_blocker_prevents_private_ip_access", "asyncio", "pytestmark", "TestSecurityIntegration", "test_integration.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0003687269999659293, "outcome": "passed"}, "call": {"duration": 0.0009756469999615547, "outcome": "passed"}, "teardown": {"duration": 0.0002763549999826864, "outcome": "passed"}}, {"nodeid": "tests/test_main.py::test_health_endpoint", "lineno": 13, "outcome": "passed", "keywords": ["test_health_endpoint", "test_main.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00014579099996581135, "outcome": "passed"}, "call": {"duration": 0.0027360159999716416, "outcome": "passed"}, "teardown": {"duration": 0.00010320199999114266, "outcome": "passed"}}, {"nodeid": "tests/test_main.py::test_bitbucket_status_endpoint", "lineno": 22, "outcome": "passed", "keywords": ["test_bitbucket_status_endpoint", "test_main.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00015161200002467012, "outcome": "passed"}, "call": {"duration": 0.002011796999966009, "outcome": "passed"}, "teardown": {"duration": 0.00010344300000042495, "outcome": "passed"}}, {"nodeid": "tests/test_main.py::test_jira_status_endpoint", "lineno": 30, "outcome": "passed", "keywords": ["test_jira_status_endpoint", "test_main.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0001534049999918352, "outcome": "passed"}, "call": {"duration": 0.0019136749999688618, "outcome": "passed"}, "teardown": {"duration": 0.00010200999997778126, "outcome": "passed"}}, {"nodeid": "tests/test_main.py::test_bitbucket_webhook_success", "lineno": 38, "outcome": "passed", "keywords": ["test_bitbucket_webhook_success", "test_main.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0001539270000421311, "outcome": "passed"}, "call": {"duration": 0.002420699000026616, "outcome": "passed"}, "teardown": {"duration": 0.00012040400002888418, "outcome": "passed"}}, {"nodeid": "tests/test_main.py::test_async_functionality", "lineno": 48, "outcome": "passed", "keywords": ["test_async_functionality", "asyncio", "pytestmark", "test_main.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00037444800000230316, "outcome": "passed"}, "call": {"duration": 0.0002030180000360815, "outcome": "passed"}, "teardown": {"duration": 0.00025174799998239905, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_clean_prompt_passes", "lineno": 34, "outcome": "passed", "keywords": ["test_clean_prompt_passes", "TestPromptSanitization", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00015321500001164168, "outcome": "passed"}, "call": {"duration": 0.0001406719999863526, "outcome": "passed"}, "teardown": {"duration": 0.00011230900003056377, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_injection_pattern_detected", "lineno": 40, "outcome": "passed", "keywords": ["test_injection_pattern_detected", "TestPromptSanitization", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00014982900000859445, "outcome": "passed"}, "call": {"duration": 0.00017934400000285677, "outcome": "passed"}, "teardown": {"duration": 9.366399996224573e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_strict_mode_raises_exception", "lineno": 55, "outcome": "passed", "keywords": ["test_strict_mode_raises_exception", "TestPromptSanitization", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00016910499999767126, "outcome": "passed"}, "call": {"duration": 0.00022314599999617712, "outcome": "passed", "log": [{"name": "vaal_ai_empire.api.sanitizers", "msg": "Dangerous patterns detected: ['(?i)(ignore|forget|disregard)\\\\s+(previous|above|all|everything|instructions|prompts|rules)\\\\b']", "args": null, "levelname": "ERROR", "levelno": 40, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../vaal_ai_empire/api/sanitizers.py", "filename": "sanitizers.py", "module": "sanitizers", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 73, "funcName": "sanitize_prompt", "created": 1769899096.5030077, "msecs": 503.0, "relativeCreated": 1263.0054950714111, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 9.554799999023089e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_soft_mode_filters_patterns", "lineno": 62, "outcome": "passed", "keywords": ["test_soft_mode_filters_patterns", "TestPromptSanitization", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00014704400001619433, "outcome": "passed"}, "call": {"duration": 0.0002211320000355954, "outcome": "passed", "log": [{"name": "vaal_ai_empire.api.sanitizers", "msg": "Dangerous patterns detected: ['(?i)(ignore|forget|disregard)\\\\s+(previous|above|all|everything|instructions|prompts|rules)\\\\b']", "args": null, "levelname": "ERROR", "levelno": 40, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../vaal_ai_empire/api/sanitizers.py", "filename": "sanitizers.py", "module": "sanitizers", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 73, "funcName": "sanitize_prompt", "created": 1769899096.503836, "msecs": 503.0, "relativeCreated": 1263.83376121521, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 9.375399997679779e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_unicode_normalization", "lineno": 70, "outcome": "passed", "keywords": ["test_unicode_normalization", "TestPromptSanitization", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00014586099996449775, "outcome": "passed"}, "call": {"duration": 0.00012952099996255129, "outcome": "passed"}, "teardown": {"duration": 9.9875999978849e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_length_truncation", "lineno": 79, "outcome": "passed", "keywords": ["test_length_truncation", "TestPromptSanitization", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00014554199998428885, "outcome": "passed"}, "call": {"duration": 0.00019747800001823634, "outcome": "passed", "log": [{"name": "vaal_ai_empire.api.sanitizers", "msg": "Prompt truncated from 10000 to 100 chars", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../vaal_ai_empire/api/sanitizers.py", "filename": "sanitizers.py", "module": "sanitizers", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 62, "funcName": "sanitize_prompt", "created": 1769899096.5053763, "msecs": 505.0, "relativeCreated": 1265.3741836547852, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 0.00011304100002007544, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_system_message_removal", "lineno": 86, "outcome": "passed", "keywords": ["test_system_message_removal", "TestPromptSanitization", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00014664299999367358, "outcome": "passed"}, "call": {"duration": 0.00013123500002620858, "outcome": "passed"}, "teardown": {"duration": 9.09799999817551e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_context_sanitization", "lineno": 94, "outcome": "passed", "keywords": ["test_context_sanitization", "TestPromptSanitization", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00016336400000227513, "outcome": "passed"}, "call": {"duration": 0.00025484499997219245, "outcome": "passed", "log": [{"name": "vaal_ai_empire.api.sanitizers", "msg": "Dangerous patterns detected: ['(?i)(ignore|forget|disregard)\\\\s+(previous|above|all|everything|instructions|prompts|rules)\\\\b']", "args": null, "levelname": "ERROR", "levelno": 40, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../vaal_ai_empire/api/sanitizers.py", "filename": "sanitizers.py", "module": "sanitizers", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 73, "funcName": "sanitize_prompt", "created": 1769899096.506936, "msecs": 506.0, "relativeCreated": 1266.9339179992676, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}, {"name": "vaal_ai_empire.api.sanitizers", "msg": "Dangerous patterns detected: ['(?i)(ignore|forget|disregard)\\\\s+(previous|above|all|everything|instructions|prompts|rules)\\\\b']", "args": null, "levelname": "ERROR", "levelno": 40, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../vaal_ai_empire/api/sanitizers.py", "filename": "sanitizers.py", "module": "sanitizers", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 73, "funcName": "sanitize_prompt", "created": 1769899096.5070052, "msecs": 507.0, "relativeCreated": 1267.003059387207, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 9.366399996224573e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestPromptSanitization::test_webhook_payload_sanitization", "lineno": 110, "outcome": "passed", "keywords": ["test_webhook_payload_sanitization", "TestPromptSanitization", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0001476350000189086, "outcome": "passed"}, "call": {"duration": 0.0006032439999898997, "outcome": "passed", "log": [{"name": "vaal_ai_empire.api.sanitizers", "msg": "Dangerous patterns detected: ['(?i)(ignore|forget|disregard)\\\\s+(previous|above|all|everything|instructions|prompts|rules)\\\\b']", "args": null, "levelname": "ERROR", "levelno": 40, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../vaal_ai_empire/api/sanitizers.py", "filename": "sanitizers.py", "module": "sanitizers", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 73, "funcName": "sanitize_prompt", "created": 1769899096.5079787, "msecs": 507.0, "relativeCreated": 1267.9765224456787, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 9.69910000208074e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_private_ip_detection", "lineno": 129, "outcome": "passed", "keywords": ["test_private_ip_detection", "TestSSRFProtection", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.000168794000046546, "outcome": "passed"}, "call": {"duration": 0.00020276799995144756, "outcome": "passed"}, "teardown": {"duration": 9.484699995709889e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_public_ip_allowed", "lineno": 145, "outcome": "passed", "keywords": ["test_public_ip_allowed", "TestSSRFProtection", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0001461919999883321, "outcome": "passed"}, "call": {"duration": 0.00018130800003746117, "outcome": "passed"}, "teardown": {"duration": 0.00010404400001107206, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_metadata_endpoint_blocked", "lineno": 158, "outcome": "passed", "keywords": ["test_metadata_endpoint_blocked", "TestSSRFProtection", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0001442889999907493, "outcome": "passed"}, "call": {"duration": 0.00012103500000648637, "outcome": "passed"}, "teardown": {"duration": 9.9454999997306e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_invalid_scheme_rejected", "lineno": 165, "outcome": "passed", "keywords": ["test_invalid_scheme_rejected", "TestSSRFProtection", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00014419900003304065, "outcome": "passed"}, "call": {"duration": 0.00015616000001728025, "outcome": "passed"}, "teardown": {"duration": 9.191099996996854e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_domain_allowlist", "lineno": 180, "outcome": "passed", "keywords": ["test_domain_allowlist", "TestSSRFProtection", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00014835600001106286, "outcome": "passed"}, "call": {"duration": 0.0025249740000390375, "outcome": "passed"}, "teardown": {"duration": 0.00012525300002153017, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_domain_blocklist", "lineno": 193, "outcome": "passed", "keywords": ["test_domain_blocklist", "TestSSRFProtection", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00015114100000346298, "outcome": "passed"}, "call": {"duration": 0.0001395710000338113, "outcome": "passed"}, "teardown": {"duration": 9.522699997432937e-05, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_dns_rebinding_protection", "lineno": 201, "outcome": "passed", "keywords": ["test_dns_rebinding_protection", "__wrapped__", "patchings", "TestSSRFProtection", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00015250400002742026, "outcome": "passed"}, "call": {"duration": 0.0005254780000427672, "outcome": "passed"}, "teardown": {"duration": 0.00012211799997885464, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestSSRFProtection::test_safe_session_creation", "lineno": 215, "outcome": "passed", "keywords": ["test_safe_session_creation", "TestSSRFProtection", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00015337499996803672, "outcome": "passed"}, "call": {"duration": 0.03875572899994495, "outcome": "passed"}, "teardown": {"duration": 0.00011944300001687225, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestWebhookSecurity::test_webhook_valid_signature", "lineno": 231, "outcome": "passed", "keywords": ["test_webhook_valid_signature", "TestWebhookSecurity", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00016316399995730535, "outcome": "passed"}, "call": {"duration": 0.0019733159999759664, "outcome": "passed"}, "teardown": {"duration": 0.0001100660000474818, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestWebhookSecurity::test_webhook_invalid_signature", "lineno": 251, "outcome": "passed", "keywords": ["test_webhook_invalid_signature", "TestWebhookSecurity", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00015648200002260637, "outcome": "passed"}, "call": {"duration": 0.0015382849999809878, "outcome": "passed"}, "teardown": {"duration": 0.00010174999999890133, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestWebhookSecurity::test_webhook_missing_signature", "lineno": 270, "outcome": "passed", "keywords": ["test_webhook_missing_signature", "TestWebhookSecurity", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00015491800002109812, "outcome": "passed"}, "call": {"duration": 0.0014639260000421928, "outcome": "passed"}, "teardown": {"duration": 0.00010178899998436464, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestRateLimiting::test_rate_limit_allows_under_threshold", "lineno": 288, "outcome": "passed", "keywords": ["test_rate_limit_allows_under_threshold", "asyncio", "pytestmark", "TestRateLimiting", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00040109700000812154, "outcome": "passed"}, "call": {"duration": 0.00023446700004114973, "outcome": "passed"}, "teardown": {"duration": 0.00022958799996786183, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestRateLimiting::test_rate_limit_blocks_over_threshold", "lineno": 299, "outcome": "passed", "keywords": ["test_rate_limit_blocks_over_threshold", "asyncio", "pytestmark", "TestRateLimiting", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0003669339999987642, "outcome": "passed"}, "call": {"duration": 0.00021006100001841332, "outcome": "passed"}, "teardown": {"duration": 0.0002217329999893991, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestWebhookDeduplication::test_dedupe_detects_duplicate", "lineno": 317, "outcome": "passed", "keywords": ["test_dedupe_detects_duplicate", "asyncio", "pytestmark", "TestWebhookDeduplication", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00033348099998420366, "outcome": "passed"}, "call": {"duration": 0.00022288499997102917, "outcome": "passed"}, "teardown": {"duration": 0.0002600639999741361, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestAuthenticationSecurity::test_missing_auth_key_rejected", "lineno": 342, "outcome": "passed", "keywords": ["test_missing_auth_key_rejected", "asyncio", "pytestmark", "TestAuthenticationSecurity", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00033520399995268235, "outcome": "passed"}, "call": {"duration": 0.0009287000000313128, "outcome": "passed", "log": [{"name": "app.main", "msg": "Invalid or missing self-healing key", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../app/main.py", "filename": "main.py", "module": "main", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 181, "funcName": "verify_self_healing_key", "created": 1769899096.5677853, "msecs": 567.0, "relativeCreated": 1327.7831077575684, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 0.00024579800003721175, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestAuthenticationSecurity::test_invalid_auth_key_rejected", "lineno": 355, "outcome": "passed", "keywords": ["test_invalid_auth_key_rejected", "asyncio", "pytestmark", "TestAuthenticationSecurity", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00033537499996327824, "outcome": "passed"}, "call": {"duration": 0.0008756109999694672, "outcome": "passed", "log": [{"name": "app.main", "msg": "Invalid or missing self-healing key", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../app/main.py", "filename": "main.py", "module": "main", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 181, "funcName": "verify_self_healing_key", "created": 1769899096.5696628, "msecs": 569.0, "relativeCreated": 1329.6606540679932, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 0.0002224350000119557, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestAuthenticationSecurity::test_valid_auth_key_accepted", "lineno": 368, "outcome": "passed", "keywords": ["test_valid_auth_key_accepted", "asyncio", "pytestmark", "TestAuthenticationSecurity", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.0003382300000112082, "outcome": "passed"}, "call": {"duration": 0.0008029859999965083, "outcome": "passed"}, "teardown": {"duration": 0.00024259200000642522, "outcome": "passed"}}, {"nodeid": "tests/test_security.py::TestSecurityIntegration::test_end_to_end_webhook_security", "lineno": 381, "outcome": "passed", "keywords": ["test_end_to_end_webhook_security", "asyncio", "pytestmark", "TestSecurityIntegration", "test_security.py", "tests", "The-lab-verse-monitoring-", ""], "setup": {"duration": 0.00035351899998659064, "outcome": "passed"}, "call": {"duration": 0.001810321999982989, "outcome": "passed", "log": [{"name": "vaal_ai_empire.api.sanitizers", "msg": "Dangerous patterns detected: ['(?i)(ignore|forget|disregard)\\\\s+(previous|above|all|everything|instructions|prompts|rules)\\\\b']", "args": null, "levelname": "ERROR", "levelno": 40, "pathname": "/home/runner/work/The-lab-verse-monitoring-/The-lab-verse-monitoring-/tests/../vaal_ai_empire/api/sanitizers.py", "filename": "sanitizers.py", "module": "sanitizers", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 73, "funcName": "sanitize_prompt", "created": 1769899096.5746255, "msecs": 574.0, "relativeCreated": 1334.6233367919922, "thread": 140079955790720, "threadName": "MainThread", "processName": "MainProcess", "process": 10603}]}, "teardown": {"duration": 0.0003614139999967847, "outcome": "passed"}}]}