version: "3.8"

services:
  localai:
    image: localai/localai:v2.16.0
    container_name: localai-mistral
    ports:
      - "8080:8080"
    environment:
      - MODELS_PATH=/models
      - THREADS=4
      - CONTEXT_SIZE=4096
      - DEBUG=true
      - API_KEY=local-ai-key-optional
    volumes:
      - ./models:/models
      - ./localai-data:/models/localai-data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/models"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - lab-verse-network

  mcp-server:
    image: python:3.12-slim
    container_name: mcp-server
    ports:
      - "8000:8000"
    volumes:
      - ./mcp-server:/app
      - ./mcp-data:/data
    working_dir: /app
    command: ["python", "-m", "mcp.server.fastmcp"]
    depends_on:
      - localai
    environment:
      - MCP_API_KEY=${MCP_API_KEY:-}
      - CONNECTOR_MOD=${CONNECTOR_MOD:-}
      - CONNECTION_STRING=${CONNECTION_STRING:-}
    restart: unless-stopped
    networks:
      - lab-verse-network

  anomaly-detection:
    build:
      context: .
      dockerfile: src/anomaly_detection/Dockerfile
    container_name: anomaly-detection-service
    ports:
      - "8085:8085"
    environment:
      - PYTHONPATH=/app
    networks:
      - lab-verse-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8085/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  ayrshare:
    build:
      context: ./ayrshare
      dockerfile: Dockerfile
    container_name: ayrshare-service
    ports:
      - "8086:8086"
    networks:
      - lab-verse-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

networks:
  lab-verse-network:
    driver: bridge

volumes:
  mcp-data:
