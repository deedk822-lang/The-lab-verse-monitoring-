name: mistral-7b-instruct
backend: llama
parameters:
  model: mistral-7b-instruct-v0.1.Q4_K_M.gguf
  temperature: 0.7
  top_k: 40
  top_p: 0.95
  max_tokens: 2048
context_size: 4096
f16: true
stopwords:
  - "</s>"
  - "[INST]"
  - "[/INST]"
template:
  chat: |
    [INST] {{.Input}} [/INST]
  completion: |
    {{.Input}}
