{
  "meta": {
    "instanceId": "lab-verse-ai-orchestration"
  },
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "ai-orchestration",
        "options": {
          "rawBody": true
        }
      },
      "id": "webhook-trigger",
      "name": "AI Orchestration Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [240, 300],
      "webhookId": "ai-orchestration"
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "const prompt = $input.first().json.prompt;\nconst useLocal = $env.USE_LOCAL === 'true' || $env.USE_LOCAL === true;\nconst fallbackToLocal = $input.first().json.fallbackToLocal || false;\n\nconst models = [\n  { name: 'openai/gpt-4o', provider: 'openrouter', cost: 0.005, privacy: 'low' },\n  { name: 'google/gemini-pro', provider: 'openrouter', cost: 0.0015, privacy: 'low' },\n  { name: 'meta/llama-3-70b-instruct', provider: 'openrouter', cost: 0.0004, privacy: 'low' },\n  { name: 'phi-3', provider: 'localai', cost: 0, privacy: 'high' },\n  { name: 'mistral-7b-instruct', provider: 'huggingface', cost: 0.0002, privacy: 'medium' }\n];\n\n// Enhanced regret calculation with provider bias\nlet regrets = $getWorkflowStaticData('global').regrets || models.map(() => [0]);\nconst newRegrets = models.map((m, i) => {\n  let baseRegret = Math.random() * 0.5;\n  \n  // Bias toward local for privacy and cost\n  if (m.provider === 'localai') {\n    baseRegret *= 0.1; // Strong preference for local\n  } else if (m.provider === 'huggingface') {\n    baseRegret *= 0.3; // Medium preference for HuggingFace\n  }\n  \n  // Factor in cost (lower cost = lower regret)\n  baseRegret += m.cost * 100;\n  \n  return baseRegret;\n});\n\nregrets = regrets.map((r, i) => [...r.slice(-9), newRegrets[i]]);\nconst maxRegrets = regrets.map(r => Math.max(...r, 0));\nconst minMaxRegret = Math.min(...maxRegrets);\nlet selectedIndex = maxRegrets.indexOf(minMaxRegret);\n\n// Override logic: Use local if preferred or on fallback\nif (useLocal || fallbackToLocal) {\n  const localIndex = models.findIndex(m => m.provider === 'localai');\n  if (localIndex !== -1) {\n    selectedIndex = localIndex;\n  }\n}\n\nconst selectedModel = models[selectedIndex];\n$setWorkflowStaticData('global', { regrets });\n\nreturn [{\n  json: {\n    model: selectedModel.name,\n    provider: selectedModel.provider,\n    prompt,\n    cost: selectedModel.cost,\n    privacy: selectedModel.privacy,\n    timestamp: new Date().toISOString()\n  }\n}];"
      },
      "id": "model-picker",
      "name": "Enhanced Model Picker",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 300]
    }
  ],
  "connections": {
    "AI Orchestration Webhook": {
      "main": [
        [
          {
            "node": "Enhanced Model Picker",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  }
}