#!/usr/bin/env python3
"""
Grafana Metrics Validator - Enhanced Version
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Verifies metrics are flowing correctly to Grafana Cloud
Validates data integrity and alert configurations
"""

import os
import sys
from datetime import datetime
from typing import Dict, Optional

import requests


class GrafanaValidator:
    """Validates Grafana Cloud metrics and configuration."""

    def __init__(self):
        self.base_url = os.getenv("GRAFANA_CLOUD_PROM_URL", "").replace("/api/prom/push", "")
        self.user = os.getenv("GRAFANA_CLOUD_PROM_USER", "")
        self.api_key = os.getenv("GRAFANA_CLOUD_API_KEY", "")

        if not all([self.base_url, self.user, self.api_key]):
            print("‚ö†Ô∏è  Grafana credentials not configured. Skipping validation.")
            sys.exit(0)

    def query(self, query: str, time_param: Optional[str] = None) -> Optional[Dict]:
        """Execute PromQL query against Grafana Cloud."""
        query_url = f"{self.base_url}/api/prom/api/v1/query"

        params = {"query": query, "time": time_param or datetime.now().isoformat()}

        try:
            response = requests.get(
                query_url, params=params, auth=(self.user, self.api_key), timeout=10
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Query failed: {e}")
            return None

    def query_range(self, query: str, start: str, end: str, step: str = "15s") -> Optional[Dict]:
        """Execute range query against Grafana Cloud."""
        query_url = f"{self.base_url}/api/prom/api/v1/query_range"

        params = {"query": query, "start": start, "end": end, "step": step}

        try:
            response = requests.get(
                query_url, params=params, auth=(self.user, self.api_key), timeout=10
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Range query failed: {e}")
            return None


def validate_metrics():
    """Validate all expected metrics exist and are reporting."""
    validator = GrafanaValidator()

    print("‚ïî" + "‚ïê" * 68 + "‚ïó")
    print("‚ïë" + " " * 15 + "üîç GRAFANA METRICS VALIDATION" + " " * 22 + "‚ïë")
    print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")

    metrics_to_check = [
        {
            "name": "Request Total",
            "query": "ai_provider_request_total",
            "description": "Total number of requests per provider",
            "expected_labels": ["provider", "model", "status"],
        },
        {
            "name": "Error Total",
            "query": "ai_provider_errors_total",
            "description": "Total number of errors per provider",
            "expected_labels": ["provider", "error_type"],
        },
        {
            "name": "Request Duration",
            "query": "ai_provider_request_duration_seconds",
            "description": "Request latency histogram",
            "expected_labels": ["provider", "model"],
        },
        {
            "name": "Token Usage",
            "query": "ai_provider_tokens_total",
            "description": "Total tokens consumed",
            "expected_labels": ["provider", "model"],
        },
        {
            "name": "Python Agent Metrics",
            "query": 'ai_provider_request_duration_seconds{source="python-agent"}',
            "description": "Metrics from Python test agent",
            "expected_labels": ["provider", "model", "source"],
        },
    ]

    results = []

    for metric in metrics_to_check:
        print(f"\n{'‚îÄ' * 70}")
        print(f"üìä Checking: {metric['name']}")
        print(f"   {metric['description']}")
        print(f"   Query: {metric['query']}")

        result = validator.query(metric["query"])

        if result and result.get("status") == "success":
            data = result.get("data", {})
            result_data = data.get("result", [])

            if result_data:
                print(f"   ‚úÖ Metric found: {len(result_data)} series")

                # Check labels
                sample = result_data[0].get("metric", {})
                found_labels = set(sample.keys())
                expected_labels = set(metric.get("expected_labels", []))

                if expected_labels.issubset(found_labels):
                    print(f"   ‚úÖ Labels validated: {', '.join(expected_labels)}")
                else:
                    missing = expected_labels - found_labels
                    print(f"   ‚ö†Ô∏è  Missing labels: {', '.join(missing)}")

                # Show sample values
                print("   üìà Sample series:")
                for i, series in enumerate(result_data[:3]):  # Show first 3
                    metric_labels = series.get("metric", {})
                    value = series.get("value", [None, "N/A"])[1]
                    labels_str = ", ".join([f"{k}={v}" for k, v in metric_labels.items()])
                    print(f"      {i + 1}. {labels_str} = {value}")

                results.append(
                    {"name": metric["name"], "status": "success", "series_count": len(result_data)}
                )
            else:
                print("   ‚ö†Ô∏è  Metric exists but no data")
                results.append({"name": metric["name"], "status": "no_data"})
        else:
            print("   ‚ùå Metric not found or query failed")
            results.append({"name": metric["name"], "status": "failed"})

    # Summary
    print(f"\n{'‚ïê' * 70}")
    print("üìä VALIDATION SUMMARY")
    print(f"{'‚ïê' * 70}\n")

    successful = [r for r in results if r["status"] == "success"]
    no_data = [r for r in results if r["status"] == "no_data"]
    failed = [r for r in results if r["status"] == "failed"]

    print(f"‚úÖ Metrics with data: {len(successful)}/{len(results)}")
    print(f"‚ö†Ô∏è  Metrics without data: {len(no_data)}/{len(results)}")
    print(f"‚ùå Failed metrics: {len(failed)}/{len(results)}")

    if no_data:
        print("\n‚ö†Ô∏è  Metrics without data:")
        for r in no_data:
            print(f"   - {r['name']}")
        print("\nüí° Tip: Run live_test_agent.py to generate data")

    if failed:
        print("\n‚ùå Failed metrics:")
        for r in failed:
            print(f"   - {r['name']}")

    print(f"\n{'‚ïê' * 70}\n")

    return len(failed) == 0 and len(no_data) == 0


def check_data_freshness():
    """Check if metrics are being updated recently."""
    validator = GrafanaValidator()

    print("‚ïî" + "‚ïê" * 68 + "‚ïó")
    print("‚ïë" + " " * 18 + "üïê DATA FRESHNESS CHECK" + " " * 26 + "‚ïë")
    print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")

    # Check last update time
    query = "ai_provider_request_total"
    result = validator.query(query)

    if result and result.get("status") == "success":
        data = result.get("data", {})
        result_data = data.get("result", [])

        if result_data:
            latest_timestamp = 0
            for series in result_data:
                timestamp = float(series.get("value", [0, 0])[0])
                if timestamp > latest_timestamp:
                    latest_timestamp = timestamp

            if latest_timestamp > 0:
                last_update = datetime.fromtimestamp(latest_timestamp)
                age_seconds = (datetime.now() - last_update).total_seconds()

                print(f"üìÖ Last Update: {last_update.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"‚è±Ô∏è  Age: {age_seconds:.0f} seconds ago")

                if age_seconds < 60:
                    print("‚úÖ Data is fresh (< 1 minute old)")
                    return True
                elif age_seconds < 300:
                    print(f"‚ö†Ô∏è  Data is slightly stale ({age_seconds / 60:.1f} minutes old)")
                    return True
                else:
                    print(f"‚ùå Data is stale ({age_seconds / 60:.1f} minutes old)")
                    print("üí° Check if metrics push is working")
                    return False
            else:
                print("‚ùå No timestamp data available")
                return False
        else:
            print("‚ùå No data found")
            return False
    else:
        print("‚ùå Query failed")
        return False


def validate_slo_query():
    """Validate the SLO availability query works correctly."""
    validator = GrafanaValidator()

    print("\n‚ïî" + "‚ïê" * 68 + "‚ïó")
    print("‚ïë" + " " * 20 + "üéØ SLO QUERY VALIDATION" + " " * 23 + "‚ïë")
    print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")

    slo_query = (
        "1 - (sum(rate(ai_provider_errors_total[5m])) / sum(rate(ai_provider_request_total[5m])))"
    )

    print(f"Query: {slo_query}\n")

    result = validator.query(slo_query)

    if result and result.get("status") == "success":
        data = result.get("data", {})
        result_data = data.get("result", [])

        if result_data and len(result_data) > 0:
            value = float(result_data[0].get("value", [None, 0])[1])
            percentage = value * 100

            print("‚úÖ SLO Query successful")
            print(f"üìä Current Availability: {percentage:.2f}%")

            if percentage >= 99:
                print("üèÜ Excellent availability (‚â• 99%)")
            elif percentage >= 95:
                print("‚úÖ Good availability (‚â• 95%)")
            elif percentage >= 90:
                print("‚ö†Ô∏è  Acceptable availability (‚â• 90%)")
            else:
                print("‚ùå Poor availability (< 90%)")

            return True
        else:
            print("‚ö†Ô∏è  Query returned no data")
            print("üí° This is normal if no requests have been made recently")
            return False
    else:
        print("‚ùå SLO query failed")
        return False


def check_provider_distribution():
    """Check distribution of requests across providers."""
    validator = GrafanaValidator()

    print("\n‚ïî" + "‚ïê" * 68 + "‚ïó")
    print("‚ïë" + " " * 16 + "üîÑ PROVIDER DISTRIBUTION" + " " * 26 + "‚ïë")
    print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")

    query = "sum(ai_provider_request_total) by (provider)"
    result = validator.query(query)

    if result and result.get("status") == "success":
        data = result.get("data", {})
        result_data = data.get("result", [])

        if result_data:
            providers = []
            total_requests = 0

            for series in result_data:
                provider = series.get("metric", {}).get("provider", "unknown")
                count = float(series.get("value", [None, 0])[1])
                providers.append({"provider": provider, "count": count})
                total_requests += count

            providers.sort(key=lambda x: x["count"], reverse=True)

            print(f"Total Requests: {int(total_requests)}\n")
            print(f"{'Provider':<15} {'Requests':<12} {'Percentage':<12} {'Bar'}")
            print("‚îÄ" * 70)

            for p in providers:
                percentage = (p["count"] / total_requests * 100) if total_requests > 0 else 0
                bar = "‚ñà" * int(percentage / 2)
                print(f"{p['provider']:<15} {int(p['count']):<12} {percentage:>6.1f}%     {bar}")

            # Check if fallback is working
            if len(providers) > 1:
                print("\n‚úÖ Multiple providers active - fallback working")
            else:
                print("\n‚ö†Ô∏è  Only one provider active - verify fallback configuration")

            return True
        else:
            print("‚ö†Ô∏è  No provider data found")
            return False
    else:
        print("‚ùå Query failed")
        return False


def check_latency_percentiles():
    """Check latency percentiles across providers."""
    validator = GrafanaValidator()

    print("\n‚ïî" + "‚ïê" * 68 + "‚ïó")
    print("‚ïë" + " " * 18 + "‚ö° LATENCY PERCENTILES" + " " * 27 + "‚ïë")
    print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")

    percentiles = [50, 95, 99]

    for p in percentiles:
        query = f"histogram_quantile({p / 100}, sum(rate(ai_provider_request_duration_seconds_bucket[5m])) by (le, provider))"
        result = validator.query(query)

        if result and result.get("status") == "success":
            data = result.get("data", {})
            result_data = data.get("result", [])

            if result_data:
                print(f"P{p} Latency:")
                for series in result_data:
                    provider = series.get("metric", {}).get("provider", "unknown")
                    latency = float(series.get("value", [None, 0])[1])
                    print(f"  {provider:<12} {latency:.3f}s")
                print()


def run_comprehensive_validation():
    """Run all validation checks."""
    print("\n" + "‚ïî" + "‚ïê" * 68 + "‚ïó")
    print("‚ïë" + " " * 10 + "üîç COMPREHENSIVE GRAFANA VALIDATION" + " " * 21 + "‚ïë")
    print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")

    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    results = {
        "metrics": validate_metrics(),
        "freshness": check_data_freshness(),
        "slo": validate_slo_query(),
        "providers": check_provider_distribution(),
    }

    check_latency_percentiles()

    # Final summary
    print("‚ïî" + "‚ïê" * 68 + "‚ïó")
    print("‚ïë" + " " * 22 + "üìä FINAL RESULTS" + " " * 29 + "‚ïë")
    print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")

    all_passed = all(results.values())

    print(f"Metrics Validation:      {'‚úÖ PASSED' if results['metrics'] else '‚ùå FAILED'}")
    print(f"Data Freshness:          {'‚úÖ PASSED' if results['freshness'] else '‚ùå FAILED'}")
    print(f"SLO Query:               {'‚úÖ PASSED' if results['slo'] else '‚ö†Ô∏è  NO DATA'}")
    print(f"Provider Distribution:   {'‚úÖ PASSED' if results['providers'] else '‚ö†Ô∏è  NO DATA'}")

    print("\n" + "‚îÄ" * 70)

    if all_passed:
        print("üéâ All validations passed!")
        print("‚úÖ Grafana Cloud is properly configured and receiving metrics")
    else:
        print("‚ö†Ô∏è  Some validations failed or returned no data")
        print("\nüí° Troubleshooting steps:")
        if not results["metrics"]:
            print("   1. Verify GRAFANA_CLOUD_* environment variables are set")
            print("   2. Check Grafana Cloud credentials are valid")
        if not results["freshness"]:
            print("   3. Verify pushToGrafana.js is running")
            print("   4. Check Vercel deployment logs for errors")
        if not results["slo"] or not results["providers"]:
            print("   5. Run live_test_agent.py to generate test data")
            print("   6. Wait 30-60 seconds for metrics to propagate")

    print("\n" + "‚ïê" * 70 + "\n")

    return all_passed


if __name__ == "__main__":
    try:
        success = run_comprehensive_validation()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Validation interrupted by user")
        sys.exit(130)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        sys.exit(1)
