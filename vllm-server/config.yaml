model:
  name: "Qwen/Qwen-72B-Instruct"
  context_length: 32768
<<<<<<< HEAD

server:
  port: 8000
  tensor_parallel_size: 4

=======

server:
  port: 8000
  tensor_parallel_size: 4

>>>>>>> c00699664d3818edf437bf12f56f434451084e1b
performance:
  gpu_memory_utilization: 0.95
  max_num_batched_tokens: 8192
